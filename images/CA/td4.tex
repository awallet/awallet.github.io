\documentclass[11pt]{exam}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noprintanswers % pour enlever les r√©ponses
%\printanswers

\unframedsolutions
\SolutionEmphasis{\itshape\small}
\renewcommand{\solutiontitle}{\noindent\textbf{A: }}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%\usepackage[margin=0.73in]{geometry}
%\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

%\usepackage{fullpage}


\usepackage{hyperref}
\usepackage{appendix}
\usepackage{enumerate}


\usepackage{times,graphicx,epsfig,amsmath,latexsym,amssymb,verbatim}%,revsymb}
\usepackage{algorithmicx, enumitem, algpseudocode, algorithm, caption}


%%%%%%%%%%%%%%%%%%%%%
% Handling comments and versions %%%
%%%%%%%%%%%%%%%%%%%%%
\newcommand{\extra}[1]{}

\renewcommand{\comment}[1]{\texttt{[#1]}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsthm}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{proposition}[theorem]{Proposition}


\theoremstyle{definition}
\newtheorem{problem}{Problem}


\newcommand{\nc}{\newcommand}
\nc{\eps}{\varepsilon}
\nc{\RR}{{{\mathbb R}}}
\nc{\CC}{{{\mathbb C}}}
\nc{\FF}{{{\mathbb F}}}
\nc{\NN}{{{\mathbb N}}}
\nc{\ZZ}{{{\mathbb Z}}}
\nc{\PP}{{{\mathbb P}}}
\nc{\QQ}{{{\mathbb Q}}}
\nc{\UU}{{{\mathbb U}}}
\nc{\OO}{{{\mathbb O}}}
\nc{\EE}{{{\mathbb E}}}


\newcommand{\field}{\mathbb{K}}
\nc{\K}{K}
\newcommand{\val}{\operatorname{val}}
\newcommand{\bigO}{\mathcal{O}}

\pretolerance=1000

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% DOCUMENT STARTS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tikz}
\usetikzlibrary{automata}
\DeclareMathOperator{\Vol}{Vol}

\begin{document}

{\noindent
   \textsc{ENS Lyon --  M1 -- Computer Algebra}
   \hfill {E.Kirshanova / A.Wallet // 2017--2018\\
  }
  \hrule
% Titre de la feuille
  \begin{center}
    {\Large\textbf{
   \textsc{Tutorial 4}
    } } 
  \end{center}
  \hrule \vspace{5mm}

\thispagestyle{empty}

\vspace{0.2cm}

%\Large

In all the exercises, $K$ is a commutative field of
characteristic not equal to 2 (the FFT is quite tricky to work
  out in characteristic 2 -- no nice roots of unity). We
assume that all operations in $\K$ cost $O(1)$. We denote $M(n)$ for
the complexity of multiplying two polynomials of degree $n$.
\vspace{-1mm}

\section{FFT as a particular multipoint evaluation}
\begin{questions}
\question Let $n = 2^k \in \mathbb{N}$, and $P$ and $Q$ be two polynomials of $K[X]$ with degree at most $n/2-1$. Explain why the FFT algorithm is a particular case of the fast multipoint evaluation algorithm. 
    
\begin{solution}
The FFT algorithm used for computing product of 2 polynomials $P$ and $Q$ of degree at most $n/2$ consists in: computing $P(\zeta)$ and $Q(\zeta)$ for all $n$-roots of unity $\zeta$. This is multipoint evaluation for $P$ and $Q$. Then we compute the product $P(\zeta)Q(\zeta)$ point by point (this takes time $O(n)$ so this in negligible in the total complexity) and then we interpolate to find a polynomial $R$ of degree at most $n$ such that $R(\zeta) = P(\zeta) Q(\zeta)$. This is interpolation.  
\end{solution}


  \question Recall the complexity of multiplying $P$ and $Q$ using the FFT algorithm. What is the general complexity of fast multi-point evaluation at $n$ points? Why is the complexity of the FFT algorithm better than in the general fast
  multipoint evaluation algorithm? 
  
  \begin{solution}
    When using the standard fast multipoint evaluation algorithm, we must do Euclidean divisions of polynomials at each step of the recursion. If they have degree $n$, then the cost is $O(M(n)\log n)$. The FFT is about evaluating at roots of unity, that is to say, the roots of $X^n-1$, when $n$ is a power of $2$. This polynomial is so cool that the remainders can be computed by hand in general. This is where we shave a $\log n$ factor and obtain a time of $O(n\log n)$.

    Let $\omega$ be a primitive $n$-th root of unity, that is to say $w^n=1$ and for all $0<j<n$, $w^j\neq 1$. In particular, this implies that $x^n-1=\prod_{j=0}^{n-1}(x-\omega^j)$ and that $w^{n/2}=-1$. As $n$ is a power of two, we can write $x^n-1=(x^{n/2}-1)(x^{n/2}+1)$. Euclidean division of, say, $P$ by these two factors can be written as $P(x) = q_0(x)(x^{n/2}-1)+r_0(x) = q_1(x)(x^{n/2}+1)+r_1(x)$, with $\deg r_i < n/2$. We can always find $P_0, P_1$ of degree $< n/2$ such that $P(x) = P_0(x)x^{n/2}+P_1(x)$. But then we see that
    $$ P(x) = P_0(x)(x^{n/2}-1)+P_0(x)+P_1(x)=P_0(x)(x^{n/2}+1)-P_0(x)+P_1(x),$$
so that $r_0(x) = P_0(x)+P_1(x)$ and $r_1(x)=P_1(x)-P_0(x)$. They can be computed using $O(n)$ additions/subtractions of $P$'s coefficients. In order to be able to apply the recursive strategy, we note that $x^{n/2}+1 = x^{n/2}-w^{n/2}.$
    
    
  % The complexity of multiplying $P$ and $Q$ using the FFT algorithm is $O(n\log n)$. The general complexity of fast multi-point evaluation at $n$ points is $O(M(n) \log n)$. The FFT algorithm use the fact that we do not evaluate at random points but at very specific points, that is roots of unity. This structure allows us to have some isomorphism when we split our polynomial and then we have to perform only one branch of the tree and use the isomorphism to reconstruct the whole tree, instead of computing all the tree.
  \end{solution}
\end{questions}

\section{Deterministic factorization}

In this exercise we develop Strassen's factorization method (sometimes called Pollard-Strassen factorization algorithm). This method \emph{deterministically} finds the prime factorization of a positive integer $N$  in time $O(N^{1/4 + \varepsilon})$. Up to $poly(\log N)$ factors, this is the fastest method known so far.

\begin{questions}
  \question Consider the simplest case when $N$ is a product of two primes, namely, $N=p \cdot q$ (assume, $p < q$). Let $d = \lceil N^{1/4}\rceil$. Show how to compute a non-trivial factor of $N$ knowing $(d^2)!\bmod N$ in time $O(M(\log N) \log\log N)$.
  
  \begin{solution}
    If we can compute $(d^2)! \bmod N$, then we just take $\gcd((d^2)!, N) = p = \gcd((d^2)! \bmod N, N)$ (observe that $(d^2)!$ must contain $p$ as one of its multiple). We can perform the gcd computation on number of bit-size $\log N$ in the aforementioned time.
  \end{solution}
  
  \question Consider the polynomial 
  \[
    f(x) = (x+1)(x+2) \cdot\ldots\cdot  (x+d) \in (\ZZ/N\ZZ)[x].
  \]
  Show how to compute $(d^2)!$ using multipoint evaluation of $f$ in time $O(M(d) \log d)$, where $M(d)$ is time needed to multiply two polynomials of degree $d$. Conclude on the running time for factoring $N$.
  \begin{solution}
    First we notice that we can compute $f(x)$ in time $O(M(d) \log d)$ using product tree. Further, we have
    \begin{align*}
      b_0 & = f(0) = 1 \cdot 2 \cdot\ldots\cdot d \\
      b_1 & = f(d) = (d+1) \cdot (d+2)\cdot \ldots\cdot (2d) \\
      \vdots \\
      b_{d-1} & = f((d-1)d) = ((d-1)d+1)\cdot\ldots\cdot d^2.
    \end{align*}
    
    We can compute $b_j \bmod N$'s in time $O(M(d) \log d)$ using multipoint evaluation. We can also compute their product in time $O(M_{\text{int}}(\log N) \log d)$, where $M_{\text{int}}(\log N)$ is complexity of multiplying two integers of bit-size $\log N$. This is clearly inferior to the multipoint evaluation.
    
    Overall, we need $O(M(d) \log d)$ time to compute a non-trivial factor of $N$. Since $M(d) = \tilde{O}(d \log d)$ and $d=N^{1/4}$, we obtain the claimed complexity.
  \end{solution}

  \question Now assume $N=p\cdot q\cdot r$. What can go wrong in the above algorithm? Suggest a method that solves this problem.
  \begin{solution}
    It can happen that $p \approx q \approx r \approx N^{1/3}$ (we usually exclude this case for $N=pq$ since we have another technique for the case $p \approx q$). In such a case, $\gcd(N, \prod_i b_i)$ can give $N$ (all the primes $p,q,r$ have got `packed' inside the $b_j$). 
			
			We identify this $b_j$ by constructing a product tree with the root $\prod_i b_i$ and $d$ leaves $(b_i)_{i \leq d}$.
			We then take the leaf $b_j$ that leads to $\gcd(N, b_j) \bmod N$(there must be only one such $b_j$), and apply the algorithm recursively on $b_j$. 
 		\end{solution}
\end{questions}

\section{Determinant}
Let $M\in \mathcal{M}_n(\mathbb{K}[X])$. Assume that all the entries of $M$ have degree at most $d$. Give an evaluation-~interpolation algorithm for computing $\det (M)$. What is its complexity ?

\begin{solution}
	We know that $\det(M)$ is a polynomial of degree at most $nd$. One can see it from the permutation formula for the determinant: $\det(M) =\sum_{\sigma \in S_n} ( \text{sgn}(\sigma) \prod_i m_{i, \sigma(i)}) $. Hence, it suffices to evaluate at $nd+1$ points all entries of $M$, compute the determinant at these $nd+1$ points and then interpolate.
	Evaluating a polynomial of degree at most $d$ at $nd+1$ points takes time $O(n(M(d)\log d))$ (splitting our $nd$ points into blocks of $d$ points). We have to do this for $n^2$ entries (polynomials), hence the total cost of all evaluations is $O(n^3(M(d)\log d))$.
	Then, we have to compute $nd+1$ determinants in $\mathbb{K}$ (at the points we have evaluated the coefficients). Each determinant in $\mathbb{K}$ costs $O(n^3)$ and hence this part costs $O(n^4d)$ in total.
	Finally, for the interpolation, we have $nd+1$ points and we want to reconstruct a polynomial of degree $nd$. This takes time $O(M(nd) \log(nd))$.
	
	Using the fact that $M(n) \leq n^2$, the first and second part that dominate (depending on the value of $d$ compared to $n$). Hence the complexity for the whole computation is $O(n^4d+n^3(M(d)\log d))$.
\end{solution}

\section{Fast CRT}
\label{CRT}

\begin{questions}
	\question Recall (any version of) the Chinese Remainder Theorem.
	
	\begin{solution}
	Let $n, m \in \ZZ$ (or in $K[X]$) be coprime. Then, for any $a,b \in \ZZ$ (or in $K[X])$, there exists $p \in \ZZ$ (or in $K[X]$) such that 
	\begin{align*}
	p &\equiv a \mod n \\
	p &\equiv b \mod m
	\end{align*}
	Moreover, $p$ is unique modulo $mn$ (i.e. all solutions $p$ differ by a multiple of $mn$).
	\end{solution}


Let $P_i \in \K[X]$ for $i \in \{0,\ldots, k-1\}$ be pairwise coprime polynomials,
with $d_i := \deg P_i$. Let $N = \prod_{i=0}^{k-1} P_i$ and $n :=
\sum_{i=0}^{k-1} d_i = \deg N$ and $k$ -- a power-of-two. 

Note some useful properties of $M(n)$: $\sum_{i=0}^{k-1} M(d_i) \leq M(n)$ ($M$ is superlinear) and  $M(2n)=O(M(n))$.

\question Let $u_0, \dots, u_{k-1}$ be polynomials with
  $\deg u_i < d_i$. Give an algorithm of complexity $O(M(n) \log n \log k)$
  to compute a polynomial $x$ of degree $< n$ such that 
  \begin{equation}
  \label{eq}
  x = u_i \mod P_i \ \ \forall i \in [k].
  \end{equation}
  (Bonus: Note that your algorithm works in the integer case 
  (if $P_i$ and $u_i$ are integers).) 
  
  \begin{solution}
  First, we start with $k = 2$. Let $U$ and $V$ be polynomials such that $UP_0 + VP_1 = 1$. We have that $UP_0 = 0 \mod P_0$ and $UP_0 = 1 \mod P_1$, and similarly for $VP_1$. Then, a solution of \ref{eq} would be $x = u_0 VP_1 + u_1 UP_0 \mod N$. Let $d = \max(d_0, d_1)$, we can compute $U$ and $V$ in time $O(M(d) \log(d))$ and hence compute $x$ in time $O(M(d)\log(d)+M(n)) = O(M(d) \log(d))$ because $n = d_0+d_1 \leq 2d$.
  Now, for an arbitrary $k$, we build a binary tree (like for evaluation). We start from the leaves and then go up to the root. At each floor of the tree, we use the subcase $k=2$ we described above. This takes time $O(M(d')\log(d'))$ for some $d'$, but we know that the sum of all $d'$ of the same floor is less that $n$, hence, using the superlinearity of $M$, we have that each floor takes time $O(M(n) \log n)$ to compute. And we have at most $\log k$ such floors.
  \end{solution}

\question Prove that one can compute all the polynomials
  $R_i := N \bmod P_i^2$ in time $O(M(n) \log k)$ (generalize fast multipoint
  evaluation). 
  
  \begin{solution}
  First, we compute $N \mod \prod_i P_i^2$. This takes time $O(M(n))$ (again using super-linearity of $M$). Then We build a tree like in fast multi-point evaluation and we reduce, from the root to the leaves. Each floor of the tree costs $O(M(n))$ (this is just euclidean division to reduce $R \mod P_1P_2$ to $R \mod P_1$ and $R \mod P_2$). And we have at most $\log k$ floors.
  \end{solution}

\question Define $S_i = (R_i/P_i)^{-1} \bmod
  P_i$. Show that $S_i$ is well defined (i.e., $R_i/P_i$ is invertible modulo $P_i$) and that one can compute all the $S_i$'s in time $O(M(n) \log
  n)$. 
  \begin{solution}
  First, we have $R_i = N + P_i^2 Q$ for some $Q$. Then $R_i$ is divisible by $P_i$ and we have $R_i/P_i = \prod_{j \neq i} P_j + P_i Q$ (perform the division in $K[X]$). Hence, we have $R_i/P_i = \prod_{j \neq i} P_j \mod P_i$ and as the $P_j$ are pairwise coprime, $\prod_{j \neq i} P_j$ is invertible modulo $P_i$. We can compute $R_i/P_i \mod P_i$ in time $O(M(d_i))$ (division in $K[X]$ of a polynomial of degree $2d_i$ by a polynomial of degree $d_i$). Then we compute $(R_i/P_i)^{-1} \mod P_i$ using Bezout  (EEA) in time $O(M(d_i) \log(d_i))$ (cf last tutorial). If we do this for all $i$, using the super-linearity of $M$ we have $O(M(n)\log n)$.
  \end{solution}

\question Prove that $x = \sum_{i=0}^{k-1} c_i N/P_i$ 
with $c_i = u_i S_i \bmod P_i$
  is a solution to question 2, and explain how to compute $x$ in
  time $O(M(n) \log n)$. % -- try to use a similar strategy to the one that was used during the class for evaluating Lagrange's formula in quasilinear time.
  
  \begin{solution}
  Write $N_1 = \prod_{0\leq i < k/2} P_i$ and $N_2 = \prod_{k/2 \leq i < k} P_i$. We have $N = N_1N_2$ and
  $$x = \sum_i c_i \frac{N}{P_i} = N_2 \sum_{0 \leq i < k/2} c_i \frac{N_1}{P_i} +  N_1 \sum_{k/2 \leq i < k} c_i \frac{N_2}{P_i} $$
 First, one can verify that such $x$ indeed satisfies $x = u_i \bmod P_i$.
  
 Second, we use this decomposition to construct a recursive algorithm. Its complexity should be the one wanted.
  \end{solution}
\end{questions}



\end{document}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
